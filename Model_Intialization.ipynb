{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b57c36eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from ta import add_all_ta_features\n",
    "from ta.utils import dropna\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression, SelectPercentile\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7596cd7e",
   "metadata": {},
   "source": [
    "# Importing data and processing it using TA lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daf2bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns X and y data in dataframe form processed and with TA lib features\n",
    "#time is 10 years\n",
    "def process_data(stock_name):\n",
    "    start = datetime.datetime(2020,4,6)\n",
    "    end = datetime.datetime(2022,4,6)\n",
    "    stock = yf.download(stock_name,start,end)\n",
    "    \n",
    "    df = add_all_ta_features(\n",
    "        stock, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\")\n",
    "    \n",
    "    df.drop(columns = [\"trend_psar_up\",\"trend_psar_down\"], inplace = True)\n",
    "    df.dropna(inplace = True)\n",
    "    \n",
    "    X = df.drop(\"Close\",axis = 1)\n",
    "    y = df[\"Close\"]\n",
    "\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de84d87a",
   "metadata": {},
   "source": [
    "# K- Feature Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a681d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_best_selector(X, y):\n",
    "    select = SelectKBest(f_regression, k = 25)\n",
    "    select.fit_transform(X, y)\n",
    "    cols = select.get_support(indices=True)\n",
    "    X = X.iloc[:,cols]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377d5a84",
   "metadata": {},
   "source": [
    "# PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d27e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_selector(X, y):    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, shuffle = None)\n",
    "    \n",
    "    def get_variance(comp_count, train, test):\n",
    "      pca = PCA(n_components=comp_count)\n",
    "      train = pca.fit_transform(train)\n",
    "      test = pca.transform(test)\n",
    "\n",
    "      return pca.explained_variance_ratio_, train, test, pca\n",
    "\n",
    "    components = 1\n",
    "    explained_variance = 0\n",
    "    while np.sum(explained_variance) < .95:\n",
    "\n",
    "        explained_variance, X_train_fit, X_test_fit, pca = get_variance(components, X_train, X_test)\n",
    "\n",
    "        components += 1\n",
    "\n",
    "    # Reformats the principal components into a usable dictionary\n",
    "    vals = np.array(pca.components_).T\n",
    "    #print(vals)\n",
    "    pc_lst = [f'PC{num+1}' for num in range(len(vals.T))]\n",
    "    data = pd.DataFrame(vals, columns=pc_lst, index=X.columns)\n",
    "    # Creates an empty dictionary to store feature importance\n",
    "    feature_importance = {feature:0 for feature in X.columns}\n",
    "\n",
    "    # Populates dictionary with their principal component correspondants\n",
    "    for key in feature_importance.keys():\n",
    "      feature_importance[key] = sum(data.loc[key])\n",
    "\n",
    "    # Creates an ordered list of the importance values from the dictionary\n",
    "    features_ordered = list(feature_importance.items())\n",
    "    features_ordered = sorted(features_ordered, key = lambda x: x[1])[::-1]\n",
    "\n",
    "    # Creates a list of bar heights and labels for each val above a threshold\n",
    "    thresh  = 0.3\n",
    "    height = [val for name, val in features_ordered if val >= thresh]\n",
    "    x = [name for name, val in features_ordered][:len(height)]\n",
    "    X = X.loc[:,x]\n",
    "    print(X)\n",
    "    print(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a040709",
   "metadata": {},
   "source": [
    "# Lasso Regression feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "109a7489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the lasso regression class\n",
    "class LassoRegression() :\n",
    "\n",
    "  # define the constructor and pass\n",
    "  # learning rate, iterations i.e epochs and l1 penality for Lasso\n",
    "  def __init__( self, lr, epochs, l1_penality ) :\n",
    "\n",
    "      self.lr = lr\n",
    "      self.epochs = epochs\n",
    "      self.l1_penality = l1_penality\n",
    "      \n",
    "  # fit the model on training data\n",
    "  def fit( self, X, Y ) :\n",
    "      \n",
    "      # no_of_training_examples, no_of_features\n",
    "      self.m, self.n = X.shape\n",
    "      \n",
    "      # weight initialization\n",
    "      self.W = np.zeros( self.n )\n",
    "      \n",
    "      self.b = 0\n",
    "      self.X = X\n",
    "      self.Y = Y\n",
    "      \n",
    "      # gradient descent learning\n",
    "      for i in range( self.epochs ) :\n",
    "          self.update_weights()\n",
    "      return self\n",
    "\n",
    "  # function to update weights in gradient descent\n",
    "  def update_weights( self ) :\n",
    "\n",
    "      Y_pred = self.predict( self.X )\n",
    "      \n",
    "      # calculate gradients\n",
    "      dW = np.zeros( self.n )\n",
    "\n",
    "      # add or subtract penalty depending upon positivity or negativity of weights\n",
    "      for j in range( self.n ):\n",
    "          if self.W[j] > 0 :\n",
    "              dW[j] = ( - ( 2 * ( self.X[:, j] ).dot( self.Y - Y_pred ) )\n",
    "                      \n",
    "                      + self.l1_penality ) / self.m\n",
    "          else :\n",
    "              dW[j] = ( - ( 2 * ( self.X[:, j] ).dot( self.Y - Y_pred ) )\n",
    "                      \n",
    "                      - self.l1_penality ) / self.m\n",
    "\n",
    "      db = - 2 * np.sum( self.Y - Y_pred ) / self.m\n",
    "      \n",
    "      # update weights\n",
    "      self.W = self.W - self.lr * dW\n",
    "      self.b = self.b - self.lr * db\n",
    "      \n",
    "      return self\n",
    "\n",
    "  # predict the output\n",
    "  def predict( self, X ) :\n",
    "      return X.dot( self.W ) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e81c5e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_lasso(X_train, X_test, y_train, y_test):\n",
    "  # Model training\n",
    "  model = LassoRegression( epochs = 1000, lr = 0.01, l1_penality = 500 )\n",
    "  model.fit( X_train, y_train )\n",
    "\n",
    "  # Prediction on test set\n",
    "  y_pred = model.predict( X_test )\n",
    "\n",
    "  return model.W, X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31697799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn.utils import axes_ticklabels_overlap\n",
    "def bar_importance(coeff, X_train, feature_names, thresh):\n",
    "  ''' ''' \n",
    "\n",
    "  # steps for feature importance\n",
    "  feature_importance = np.std(X_train, 0)*np.array(coeff)\n",
    "  \n",
    "  above_threshold ={}\n",
    "  # print feature name and their importance\n",
    "  for name,importance in zip(feature_names,feature_importance):\n",
    "      if abs(importance) >= thresh:\n",
    "        above_threshold[name] = importance\n",
    "\n",
    "  #create a dataframe containing feature name and their importance\n",
    "  dff = pd.DataFrame([])\n",
    "  dff['features'] = above_threshold.keys()\n",
    "  dff['importance'] = above_threshold.values()\n",
    "\n",
    "  d = dff.groupby(['features']).sum().sort_values('importance',ascending=False)\n",
    "  \n",
    "  # plot graph for feature importance\n",
    "  d['importance'].plot.bar()\n",
    "  return above_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c542c7d",
   "metadata": {},
   "source": [
    "# Making a model with all the layers and activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2be1dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = 180, activation = 'relu',return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units = 60, activation = 'relu',return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units = 60, activation = 'relu',return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units = 30))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(loss = \"mean_squared_error\", optimizer = \"adam\", metrics = \"mae\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1419187a",
   "metadata": {},
   "source": [
    "# Plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c437852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_values(pred_vals, actual_vals):\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "    plt.plot(pred_vals)\n",
    "    plt.plot(actual_vals)\n",
    "    plt.show()\n",
    "    plt.savefig(i+'.jpg')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2897f9cc",
   "metadata": {},
   "source": [
    "# Predictor function\n",
    "\n",
    "Normalises data, feeds it into the model and gets prediction. Next, it plots the data using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4d9c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X, y):\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    y = np.array(y)\n",
    "        \n",
    "    X_transformed = scaler.fit_transform(X)\n",
    "    y_transformed = scaler.fit_transform(y.reshape(-1,1))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_transformed, y_transformed, test_size = 0.2, shuffle = None)\n",
    "    \n",
    "    train_len = len(X_train)\n",
    "    test_len = len(X_test)\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    X_train = X_train.reshape(train_len,-1,1)\n",
    "    \n",
    "    predictor = make_model()\n",
    "    \n",
    "    predictor.fit(X_train, y_train, epochs = 10)\n",
    "    \n",
    "    X_test = np.array(X_test)\n",
    "    X_test = X_test.reshape(test_len,-1,1)\n",
    "    y_test = np.reshape(y_test,(-1,1))\n",
    "    \n",
    "    \n",
    "    y_pred = predictor.predict(X_test)\n",
    "    y_pred_inv_transformed = scaler.inverse_transform(y_pred)\n",
    "    y_actual_inv_transformed = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    plot_values(y_pred_inv_transformed, y_actual_inv_transformed)   \n",
    "    \n",
    "    print(\"The r2 score of this prediction is : \", r2_score(y_actual_inv_transformed, y_pred_inv_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed74d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lass_create_model(X, y):\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    y = np.array(y)\n",
    "    \n",
    "    X_transformed = scaler.fit_transform(X)\n",
    "    y_transformed = scaler.fit_transform(y.reshape(-1,1))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_transformed, y_transformed, test_size = 0.2, shuffle = None)\n",
    "    \n",
    "    weight, X_train_refit = perform_lasso(X_train, X_test, y_train, y_test)\n",
    "    feature_names = X.columns\n",
    "\n",
    "    weight_thresh = 0.1\n",
    "    importance_dict = bar_importance(weight, X_train_refit, feature_names, weight_thresh)\n",
    "    \n",
    "    X_train = X_train[:,list(importance_dict.keys())]\n",
    "    X_test = X_test[:,list(importance_dict.keys())]\n",
    "    \n",
    "    train_len = len(X_train)\n",
    "    test_len = len(X_test)\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    X_train = X_train.reshape(train_len,-1,1)\n",
    "    \n",
    "    predictor = make_model()\n",
    "    \n",
    "    predictor.fit(X_train, y_train, epochs = 10)\n",
    "    \n",
    "    X_test = np.array(X_test)\n",
    "    X_test = X_test.reshape(test_len,-1,1)\n",
    "    y_test = np.reshape(y_test,(-1,1))\n",
    "    \n",
    "    \n",
    "    y_pred = predictor.predict(X_test)\n",
    "    y_pred_inv_transformed = scaler.inverse_transform(y_pred)\n",
    "    y_actual_inv_transformed = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    plot_values(y_pred_inv_transformed, y_actual_inv_transformed)   \n",
    "    \n",
    "    print(\"The r2 score of this prediction is : \", r2_score(y_actual_inv_transformed, y_pred_inv_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd6d1004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_kbest_func(name):\n",
    "    X, y = process_data(name)\n",
    "    new_X, new_y = K_best_selector(X, y)\n",
    "    create_model(new_X, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "007d8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_pca_func(name):\n",
    "    X, y = process_data(name)\n",
    "    new_X, new_y = pca_selector(X, y)\n",
    "    create_model(new_X, new_y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1caada13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_lasso_func(name):\n",
    "    X, y = process_data(name)\n",
    "    lass_create_model(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ae0039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks =  ['AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "833f3751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7460/2212446966.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstocks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mfinal_lasso_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7460/1482104964.py\u001b[0m in \u001b[0;36mfinal_lasso_func\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfinal_lasso_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mlass_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7460/465354441.py\u001b[0m in \u001b[0;36mlass_create_model\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_transformed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_transformed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_refit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperform_lasso\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7460/4262413617.py\u001b[0m in \u001b[0;36mperform_lasso\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m      2\u001b[0m   \u001b[1;31m# Model training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLassoRegression\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1_penality\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m   \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[1;31m# Prediction on test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7460/757376749.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m     25\u001b[0m       \u001b[1;31m# gradient descent learning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7460/757376749.py\u001b[0m in \u001b[0;36mupdate_weights\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     43\u001b[0m                       + self.l1_penality ) / self.m\n\u001b[0;32m     44\u001b[0m           \u001b[1;32melse\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m               dW[j] = ( - ( 2 * ( self.X[:, j] ).dot( self.Y - Y_pred ) )\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                       - self.l1_penality ) / self.m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "for i in stocks:\n",
    "    final_lasso_func(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8621a871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40a2c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
